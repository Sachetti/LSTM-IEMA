# -*- coding: utf-8 -*-
"""ProjetoIoT.ipynb
Author: Lucas Sachetti, Mastering in Computer Science at Universidade Federal do EspÃ­rito Santo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1csBG7gTpeOFcQkVWDkP5vSQfeOWKyskh
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# from google.colab import drives
# drive.mount("/content/drive")

#Import the dataset
import matplotlib.pyplot as plt
data = pd.read_csv('/home/lucas/Documents/Mestrado/IoT/LSTM-IEMA/Dados_IEMA_2020_CSV2.csv', delimiter = ';')
#data = numpy.loadtxt('/content/drive/My Drive/my_directory/example.csv', delimiter = ';')

#data
dfPM  = data['PM25ES']
plt.figure(figsize=(10, 6))
plt.plot(dfPM) #zooming
plt.savefig('PM25ES.pdf')
# plt.show()

#data

df = data[['Time','PM25ES']]
#df

#Interpolating the null data
df['PM25ES'] = df['PM25ES'].interpolate(method='values')
plt.figure(figsize=(10, 6))
plt.plot(df['PM25ES'][4500:5300]) #zooming
plt.savefig('PM25ES-escalado.pdf')

#Getting only the data that we'll use in LSTM
dfPM = df['PM25ES']


#This function split the data into pieces of memory, the n_steps is the memory length of the LSTM
from numpy import array
def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)


#Splitting the data, we defined a memory length=9. It means that we will read 9 samples and try to predict the next one.
X, y = split_sequence(dfPM, 9)


import tensorflow as tf
import math
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

# fix random seed for reproducibility
np.random.seed(7)

#======================== One training case, only for tests =================================#

# define model
model = Sequential()
model.add(LSTM(50, activation='relu', input_shape=(9, 1)))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mse')

# for i in range(len(X_days)):
#   X_days[i] = X_days[i].reshape((X_days[i].shape[0], X_days[i].shape[1], 1))

X = X.reshape((X.shape[0], X.shape[1], 1))

#split the dataset to 70% for traning/validation and 30% for test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)

# X_train, X_test, y_train, y_test = train_test_split(X_days[1], y_days[1], test_size=0.3, random_state=1)

# fit model
model.fit(X_train, y_train, epochs=200, verbose=0)

predicted = model.predict(X_test)

predicted

plt.plot(y_test)
plt.plot(predicted)
plt.axis([0, 100, 0, 100])
plt.savefig('predicted-teste.pdf')
# plt.show()

print(keras.metrics.mean_squared_error(y_test, predicted).numpy())
print(keras.metrics.mean_absolute_error(y_test, predicted).numpy())

#makinig naive forecast to compare the results
naive_forecast = y_test.copy()
naive_forecast[0] = y_test[-1]
naive_forecast[1:-1] = y_test[0:-2]

plt.figure(figsize=(10, 6))
plt.plot(y_test)
plt.plot(naive_forecast)
plt.axis([0, 50, 0, 50])
plt.savefig('naive-teste.pdf')
# plt.show()

#seeing the erro matrics
print(keras.metrics.mean_squared_error(y_test, naive_forecast).numpy())
print(keras.metrics.mean_absolute_error(y_test, naive_forecast).numpy())

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
# from google.colab import files
# src = list(files.upload().values())[0]
# open('/home/lucas/Documents/Mestrado/IoT/LSTM-IEMA/time_series_functions.py','wb').write(src)



#making a file to print the results
saida = open("saida.csv", "a")

string_cabecalho = "Layers;Function;Nodes;Epochs;MSE;RMSE;MAE\n"
saida.write(string_cabecalho)
# saida.write("Resultados Naive Prediction \n\n")
# saida.write(str(keras.metrics.mean_squared_error(y_test, naive_forecast).numpy()))
# saida.write(str(keras.metrics.mean_squared_error(y_test, naive_forecast).numpy()))


import time_series_functions as tsf
import json

results = json.dumps(tsf.gerenerate_metric_results(y_test, predicted))
results_naive = json.dumps(tsf.gerenerate_metric_results(y_test, naive_forecast))

# saida.write(str(model.summary()))
# saida.write(results_naive)

# saida.write("\n\n")

# model.summary(print_fn=lambda x: saida.write(x + '\n'))
# saida.write("\nResultados do Modelo\n\n")
# saida.write(results)

print(tsf.gerenerate_metric_results(y_test, naive_forecast))
print(tsf.gerenerate_metric_results(y_test, predicted))


#========================= Now is the core of the project, we iterate some parameters to verify the performance of each of them ======================================#

#Iterates the number of nodes/neurons, it depends of the dataset length
nodes = [49, 61, 70, 82, 98, 123, 164, 246]
#The activation function too
function = ['relu', 'sigmoid', 'tanh', 'softmax']
for f in function:
  for n in nodes:
    # define model
    model = Sequential()
    model.add(LSTM(n, activation=f, input_shape=(9, 1)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')

    # fit model
    #finaly we iterate the number of epochs
    epocas = [100, 200, 500, 1000]
    for e in epocas:
      model.fit(X_train, y_train, epochs=e, verbose=0)

      predicted = model.predict(X_test)

      predicted

      string_saida = 'predicted-teste-function-' + f + '-epochs' + str(e) + '-nodes' + str(n) +'.pdf'

      #plotting
      plt.plot(y_test)
      plt.plot(predicted)
      plt.axis([0, 100, 0, 100])
      plt.savefig(string_saida)
      plt.clf()
      
      # results = json.dumps(tsf.gerenerate_metric_results(y_test, predicted))

      #making the erro metrics to see the performance
      mse = tsf.mean_square_error(y_test, predicted)
      rmse = tsf.root_mean_square_error(y_test, predicted)
      mae = tsf.mean_absolute_error(y_test, predicted)

      results = "1;" + f + ";" + str(n) + ";" + str(e) + ";" + str(mse) + ";" + str(rmse) + ";" + str(mae) + "\n"
      
      # print("mse: ", mse, ", rmse: ", rmse, ", mae: ", mae)
      print("\nconcluido\n")

      # model.summary(print_fn=lambda x: saida.write(x + '\n'))
      # saida.write("\nResultados do Modelo\n\n")
      saida.write(results)


